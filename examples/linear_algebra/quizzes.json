{
  "quizzes": [
    {
      "id": "prerequisite-assessment",
      "title": "Prerequisite Knowledge Assessment",
      "description": "Diagnostic quiz to confirm readiness for Linear Algebra.",
      "settings": { "time_limit": 20, "shuffle_answers": true, "allowed_attempts": 2, "is_diagnostic": true },
      "mastery_criteria": { "passing_score": 60, "unlock_requirement": false },
      "gamification": {
        "xp_value": 25,
        "badges": ["foundation_scout"],
        "completion_message": "Foundation assessed ‚Äì welcome to your linear‚Äëalgebra journey!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Solve for x: 3x ‚àí 7 = 2x + 5.",
          "answers": [
            { "text": "x = 12", "weight": 100, "feedback": "Correct! 3x ‚àí 2x = 5 + 7 ‚áí x = 12." },
            { "text": "x = ‚àí12", "weight": 0, "feedback": "Sign error ‚Äì remember to add 7 to both sides, not subtract." },
            { "text": "x = 2", "weight": 0, "feedback": "You subtracted 2x but forgot to move the constant correctly." },
            { "text": "x = ‚àí2", "weight": 0, "feedback": "Mixed up both the sign and constant relocation." }
          ],
          "points_possible": 2,
          "feedback": "Linear‚Äëequation fluency is essential for row‚Äëoperation work later."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "What is the slope of the line through (2,‚ÄØ3) and (5,‚ÄØ9)?",
          "answers": [
            { "text": "m = 2",  "weight": 100, "feedback": "Œîy/Œîx = (9‚àí3)/(5‚àí2) = 6/3 = 2." },
            { "text": "m = ‚àí2", "weight": 0,   "feedback": "You reversed rise/run ‚Äì check the sign of Œîy." },
            { "text": "m = ¬Ω",  "weight": 0,   "feedback": "Upside‚Äëdown: you divided 3 by 6 instead of 6 by 3." },
            { "text": "m = 6",  "weight": 0,   "feedback": "Forgot to divide by the change in x." }
          ],
          "points_possible": 2,
          "feedback": "Slope intuition foreshadows vector direction and linear growth."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Given f(x) = 2x + 1, find f(3).",
          "answers": [
            { "text": "7", "weight": 100, "feedback": "2¬∑3‚ÄØ+‚ÄØ1‚ÄØ=‚ÄØ7 ‚úîÔ∏é" },
            { "text": "6", "weight": 0,   "feedback": "Forgot to add the constant 1." },
            { "text": "9", "weight": 0,   "feedback": "Multiplied and then added incorrectly." },
            { "text": "5", "weight": 0,   "feedback": "Plugged in 2 instead of 3 ‚Äì watch the input!" }
          ],
          "points_possible": 2,
          "feedback": "Function evaluation parallels evaluating linear transformations later."
        }
      ],
      "outcomes": ["prerequisite_algebra", "prerequisite_functions", "prerequisite_geometry"]
    },

    {
      "id": "vectors-mastery-check",
      "title": "Vectors and Operations Mastery Check",
      "description": "Assess mastery of vector definitions, operations, and geometric interpretations.",
      "settings": { "time_limit": 25, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 50,
        "badges": ["vector_warrior"],
        "completion_message": "Vector mastery achieved ‚Äì arrows unlocked!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Geometrically, u‚ÄØ+‚ÄØv is represented by:",
          "answers": [
            { "text": "The diagonal of the parallelogram defined by u and v (tip‚Äëto‚Äëtail).", "weight": 100, "feedback": "Exactly ‚Äì the parallelogram law of addition." },
            { "text": "A vector perpendicular to both u and v.", "weight": 0, "feedback": "That describes the 3‚ÄëD cross‚Äëproduct direction, not addition." },
            { "text": "Halfway between u and v.", "weight": 0, "feedback": "That‚Äôs (u‚ÄØ+‚ÄØv)/2, the midpoint vector." },
            { "text": "A reflection of u across v.", "weight": 0, "feedback": "Reflection requires projection concepts, not simple addition." }
          ],
          "points_possible": 3,
          "feedback": "Visualizing addition builds later intuition for span and linear combos."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Which statement about the dot product in ‚Ñù¬≤ is TRUE?",
          "answers": [
            { "text": "If u¬∑v‚ÄØ=‚ÄØ0, then u and v are orthogonal.", "weight": 100, "feedback": "Orthogonality ‚áî 0 dot product in Euclidean spaces." },
            { "text": "u¬∑v is always positive.",                   "weight": 0,   "feedback": "Only if the angle is <‚ÄØ90¬∞." },
            { "text": "u¬∑v equals the area of the parallelogram spanned by u and v.", "weight": 0, "feedback": "Area comes from the magnitude of the cross product (in ‚Ñù¬≥)." },
            { "text": "u¬∑v equals |u|‚ÄØ+‚ÄØ|v|.",                   "weight": 0,   "feedback": "Dot product involves multiplication, not simple addition." }
          ],
          "points_possible": 3,
          "feedback": "Remember u¬∑v‚ÄØ=‚ÄØ|u||v|cos‚ÄØŒ∏ ‚Äì linking algebra to angles."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Scalar multiplication by ‚àí1 of vector w results in:",
          "answers": [
            { "text": "A vector with the same magnitude pointing opposite to w.", "weight": 100, "feedback": "Correct ‚Äì it‚Äôs a 180¬∞ rotation through the origin." },
            { "text": "A vector twice as long.",                 "weight": 0, "feedback": "Only a factor |‚àí1|‚ÄØ=‚ÄØ1, not 2." },
            { "text": "The zero vector.",                        "weight": 0, "feedback": "That‚Äôs scaling by 0, not ‚àí1." },
            { "text": "A vector orthogonal to w.",               "weight": 0, "feedback": "Orthogonality involves dot products, not sign flips." }
          ],
          "points_possible": 3,
          "feedback": "Sign matters ‚Äì we revisit this in reflections and eigen‚Äëanalysis."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "If u‚ÄØ=‚ÄØ(3,‚ÄØ4) and v‚ÄØ=‚ÄØ(1,‚ÄØ2), what is u¬∑v?",
          "answers": [
            { "text": "11", "weight": 100, "feedback": "3¬∑1‚ÄØ+‚ÄØ4¬∑2‚ÄØ=‚ÄØ3‚ÄØ+‚ÄØ8‚ÄØ=‚ÄØ11 ‚úîÔ∏é" },
            { "text": "7",  "weight": 0,   "feedback": "Added without multiplying components first." },
            { "text": "(3,‚ÄØ8)", "weight": 0, "feedback": "That‚Äôs component‚Äëwise product, not the dot product scalar." },
            { "text": "‚àö13", "weight": 0, "feedback": "That‚Äôs |u| ‚Äì dot product gives a scalar, not a magnitude here." }
          ],
          "points_possible": 3,
          "feedback": "Solid computational fluency is mandatory for projections later."
        }
      ],
      "outcomes": ["vector_operations", "dot_product_concept", "geometric_interpretation"]
    },

    {
      "id": "span-mastery-check",
      "title": "Linear Combinations and Span Mastery Check",
      "description": "Test understanding of linear combinations, span, and subspace basics.",
      "settings": { "time_limit": 25, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 50,
        "badges": ["span_navigator"],
        "completion_message": "Span mastery unlocked ‚Äì combination nation conquered!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Which expression is a linear combination of vectors u and v?",
          "answers": [
            { "text": "3u‚ÄØ+‚ÄØ2v",   "weight": 100, "feedback": "Correct ‚Äì scalars times vectors, then added." },
            { "text": "u‚ÄØ¬∑‚ÄØv",     "weight": 0,   "feedback": "Dot product produces a scalar, not a vector." },
            { "text": "||u||‚ÄØ+‚ÄØ||v||", "weight": 0, "feedback": "Adds magnitudes, not the vectors themselves." },
            { "text": "u‚ÄØ√ó‚ÄØv",     "weight": 0,   "feedback": "Cross product (in ‚Ñù¬≥) isn‚Äôt a linear combination." }
          ],
          "points_possible": 3,
          "feedback": "Linear combos drive the idea of span and basis."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "The span of {(1,‚ÄØ0), (0,‚ÄØ1)} in ‚Ñù¬≤ is:",
          "answers": [
            { "text": "All of ‚Ñù¬≤", "weight": 100, "feedback": "They are the standard basis ‚Äì you can reach any (x,y)." },
            { "text": "Only the x‚Äëaxis", "weight": 0, "feedback": "You ignored (0,‚ÄØ1)." },
            { "text": "Only the origin", "weight": 0, "feedback": "Two non‚Äëzero independent vectors span more than {0}." },
            { "text": "The line y‚ÄØ=‚ÄØx",   "weight": 0, "feedback": "That‚Äôs spanned by (1,‚ÄØ1) alone." }
          ],
          "points_possible": 3,
          "feedback": "Key: Check if the vectors are independent and in 2‚ÄëD."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "If v‚ÇÅ‚ÄØ=‚ÄØ(2,‚ÄØ1) and v‚ÇÇ‚ÄØ=‚ÄØ(4,‚ÄØ2), Span{v‚ÇÅ,‚ÄØv‚ÇÇ} is:",
          "answers": [
            { "text": "A line through the origin", "weight": 100, "feedback": "v‚ÇÇ‚ÄØ=‚ÄØ2v‚ÇÅ ‚áí dependent, so dimension‚ÄØ=‚ÄØ1." },
            { "text": "All of ‚Ñù¬≤",                 "weight": 0,   "feedback": "Need two independent vectors for the plane." },
            { "text": "Only the origin",           "weight": 0,   "feedback": "Non‚Äëzero vectors span at least a line." },
            { "text": "A plane through the origin", "weight": 0,   "feedback": "In ‚Ñù¬≤ a 'plane' is the whole space; see first option." }
          ],
          "points_possible": 3,
          "feedback": "Dependency collapses the span to lower dimension."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Which subset is a subspace of ‚Ñù¬≥?",
          "answers": [
            { "text": "{(a,b,0)¬†|¬†a,b‚ÄØ‚àà‚ÄØ‚Ñù}", "weight": 100, "feedback": "Closed under addition & scalar mult ‚Äì the xy‚Äëplane." },
            { "text": "{(a,b,c)¬†|¬†a¬†+¬†b¬†+¬†c‚ÄØ=‚ÄØ1}", "weight": 0, "feedback": "Fails the zero‚Äëvector test (0¬†+¬†0¬†+¬†0‚ÄØ‚â†‚ÄØ1)." },
            { "text": "{(a,b,c)¬†|¬†all¬†components¬†>‚ÄØ0}", "weight": 0, "feedback": "Not closed under negative scalars." },
            { "text": "{(a,b,c)¬†|¬†ab¬†=‚ÄØ0}", "weight": 0, "feedback": "Mixing multiplicative condition breaks closure." }
          ],
          "points_possible": 3,
          "feedback": "Always test 0‚Äëvector, closure under +, and closure under scalar mult."
        }
      ],
      "outcomes": ["linear_combinations", "span_concept", "subspace_identification"]
    },

    {
      "id": "systems-mastery-check",
      "title": "Linear Systems Mastery Check",
      "description": "Checks mastery of row operations, pivots, and solution‚Äëset reasoning.",
      "settings": { "time_limit": 30, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 75,
        "badges": ["equation_solver", "elimination_expert"],
        "completion_message": "System solver mastery unlocked ‚Äì pivot power engaged!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Which row operation is NOT allowed (it changes the solution set)?",
          "answers": [
            { "text": "Multiply a row by 0", "weight": 100, "feedback": "Correct ‚Äì it destroys all information in that equation." },
            { "text": "Swap two rows",      "weight": 0,   "feedback": "Permissible ‚Äì equations can change order." },
            { "text": "Add a multiple of one row to another", "weight": 0, "feedback": "Classic replacement ‚Äì safe." },
            { "text": "Multiply a row by ‚àí2", "weight": 0,   "feedback": "Scaling by non‚Äëzero keeps equivalence." }
          ],
          "points_possible": 4,
          "feedback": "Row operations must preserve the solution set."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "After reduction you obtain [0¬†0¬†0¬†|¬†7].  Conclusion?",
          "answers": [
            { "text": "The system is inconsistent ‚Äì no solution.", "weight": 100, "feedback": "Contradiction row: 0‚ÄØ=‚ÄØ7 impossible." },
            { "text": "Unique solution exists.",                  "weight": 0,   "feedback": "Contradiction vetoes uniqueness." },
            { "text": "Infinitely many solutions exist.",        "weight": 0,   "feedback": "Need free variables without contradiction." },
            { "text": "Exactly two solutions exist.",            "weight": 0,   "feedback": "No such scenario with linear systems." }
          ],
          "points_possible": 4,
          "feedback": "Watch for impossible rows ‚Äì they trump everything else."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "In RREF, free variables correspond to:",
          "answers": [
            { "text": "Columns without a leading 1 (pivot).", "weight": 100, "feedback": "Non‚Äëpivot columns ‚Üí free variables." },
            { "text": "Pivot columns.",                       "weight": 0,   "feedback": "Pivot columns are basic variables." },
            { "text": "Augmented column entries.",            "weight": 0,   "feedback": "Augmented column isn‚Äôt a variable." },
            { "text": "Rows with zeros only.",                "weight": 0,   "feedback": "Zero rows signal redundancy, not free vars." }
          ],
          "points_possible": 4,
          "feedback": "Free variables drive parameterization of infinite solution sets."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "If a 4√ó4 coefficient matrix has rank‚ÄØ=‚ÄØ4, then Ax‚ÄØ=‚ÄØb:",
          "answers": [
            { "text": "Has a unique solution for every b.", "weight": 100, "feedback": "Full rank ‚áí invertible ‚áí bijective." },
            { "text": "Has no solution.",                   "weight": 0,   "feedback": "Contradicts full rank/invertibility." },
            { "text": "Has infinitely many solutions.",     "weight": 0,   "feedback": "Free vars only occur if rank‚ÄØ<‚ÄØn." },
            { "text": "Has at most one solution if b‚ÄØ=‚ÄØ0.",  "weight": 0,   "feedback": "For b‚ÄØ=‚ÄØ0 the unique solution is x‚ÄØ=‚ÄØ0." }
          ],
          "points_possible": 4,
          "feedback": "Invertibility ties rank, determinant, and unique solutions together."
        }
      ],
      "outcomes": ["solve_linear_systems", "row_reduction", "interpret_augmented_matrix"]
    },

    {
      "id": "matrix-mastery-check",
      "title": "Matrix Algebra Mastery Check",
      "description": "Targets matrix operations, identities, and basic properties.",
      "settings": { "time_limit": 25, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 60,
        "badges": ["matrix_operator"],
        "completion_message": "Matrix mastery achieved ‚Äì algebraic superpowers activated!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "For conformable matrices A (m√ón) and B (n√óp), the (i,j) entry of AB is:",
          "answers": [
            { "text": "The dot product of row‚ÄØi of A with column‚ÄØj of B.", "weight": 100, "feedback": "Definition of matrix multiplication." },
            { "text": "The product of diagonal entries a·µ¢·µ¢ and b‚±º‚±º.",      "weight": 0,   "feedback": "Diagonal entries matter only in special cases." },
            { "text": "The sum of all entries in row‚ÄØi of A and column‚ÄØj of B.", "weight": 0, "feedback": "Need products, not raw sums." },
            { "text": "Always zero if i‚ÄØ‚â†‚ÄØj.",                               "weight": 0,   "feedback": "Only true for orthogonal row/column pairs in special matrices." }
          ],
          "points_possible": 4,
          "feedback": "Row‚àòcolumn perspective is vital for proofs and code."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "If A is 3√ó2 and B is 2√ó4, the dimensions of AB are:",
          "answers": [
            { "text": "3√ó4", "weight": 100, "feedback": "Outer dimensions: rows of A by columns of B." },
            { "text": "2√ó2", "weight": 0,   "feedback": "Check multiplication rules ‚Äì inner dims only ensure compatibility." },
            { "text": "3√ó2", "weight": 0,   "feedback": "That‚Äôs just the size of A." },
            { "text": "4√ó3", "weight": 0,   "feedback": "Result dimensions are not flipped." }
          ],
          "points_possible": 3,
          "feedback": "Dimension bookkeeping prevents illegal products."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Which statement is generally FALSE for matrix multiplication?",
          "answers": [
            { "text": "Commutative: AB‚ÄØ=‚ÄØBA.", "weight": 100, "feedback": "Order usually matters ‚Äì beware!" },
            { "text": "Associative: (AB)C‚ÄØ=‚ÄØA(BC).", "weight": 0, "feedback": "Associativity holds for matrices." },
            { "text": "Distributive: A(B‚ÄØ+‚ÄØC)‚ÄØ=‚ÄØAB‚ÄØ+‚ÄØAC.", "weight": 0, "feedback": "Distributivity is valid." },
            { "text": "Scalar‚Äëcompatible: k(AB)‚ÄØ=‚ÄØ(kA)B.", "weight": 0, "feedback": "True for any scalar k." }
          ],
          "points_possible": 4,
          "feedback": "Remember: AB may equal BA only in special cases (diagonals, etc.)."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "The 2√ó2 identity matrix is:",
          "answers": [
            { "text": "[[1,‚ÄØ0], [0,‚ÄØ1]]", "weight": 100, "feedback": "Leaves vectors unchanged ‚Äì that‚Äôs the identity." },
            { "text": "[[1,‚ÄØ1], [1,‚ÄØ1]]", "weight": 0,   "feedback": "All‚Äëones matrix changes every vector." },
            { "text": "[[0,‚ÄØ1], [1,‚ÄØ0]]", "weight": 0,   "feedback": "Permutation (reflection) matrix ‚Äì not identity." },
            { "text": "[[‚àí1,‚ÄØ0], [0,‚ÄØ‚àí1]]", "weight": 0, "feedback": "That‚Äôs ‚àíI ‚Äì scales by ‚àí1, not identity." }
          ],
          "points_possible": 3,
          "feedback": "I acts as multiplicative neutral element: AI‚ÄØ=‚ÄØIA‚ÄØ=‚ÄØA."
        }
      ],
      "outcomes": ["matrix_multiplication", "matrix_properties", "identity_matrix"]
    },

    {
      "id": "independence-mastery-check",
      "title": "Linear Independence and Basis Mastery Check",
      "description": "Drills fundamental independence relationships and basis concepts.",
      "settings": { "time_limit": 30, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 65,
        "badges": ["independence_detective", "basis_builder"],
        "completion_message": "Independence mastery achieved ‚Äì you can build any basis!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "k vectors in ‚Ñù‚Åø can be linearly independent only if:",
          "answers": [
            { "text": "k‚ÄØ‚â§‚ÄØn", "weight": 100, "feedback": "Max one pivot per column ‚Äì can‚Äôt exceed dimension." },
            { "text": "k‚ÄØ‚â•‚ÄØn", "weight": 0,   "feedback": "k‚ÄØ>‚ÄØn guarantees dependence." },
            { "text": "k‚ÄØ=‚ÄØn¬≤", "weight": 0,   "feedback": "Way too many vectors." },
            { "text": "k‚ÄØ=‚ÄØ1",  "weight": 0,   "feedback": "One vector can be independent but doesn‚Äôt generalize rule." }
          ],
          "points_possible": 4,
          "feedback": "Dimensionality bounds independence."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "A 5√ó7 matrix with rank‚ÄØ=‚ÄØ3 has nullity:",
          "answers": [
            { "text": "4", "weight": 100, "feedback": "Nullity‚ÄØ=‚ÄØ7‚ÄØ‚àí‚ÄØ3‚ÄØ=‚ÄØ4 by rank‚Äënullity." },
            { "text": "3", "weight": 0,   "feedback": "That‚Äôs the rank, not nullity." },
            { "text": "2", "weight": 0,   "feedback": "Re‚Äëevaluate rank‚Äënullity: columns‚ÄØ=‚ÄØ7." },
            { "text": "5", "weight": 0,   "feedback": "Nullity can‚Äôt exceed #columns." }
          ],
          "points_possible": 4,
          "feedback": "Kernel dimension complements column rank."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Which set forms a basis of ‚Ñù¬≥?",
          "answers": [
            { "text": "{(1,0,0),(0,1,0),(0,0,1)}", "weight": 100, "feedback": "Independent and spanning ‚Äì the gold standard." },
            { "text": "{(1,0,0),(0,1,0)}", "weight": 0, "feedback": "Only spans a plane ‚Äì need 3 independent vectors." },
            { "text": "{(1,0,0),(1,0,0),(0,1,0)}", "weight": 0, "feedback": "Duplicate ‚Üí dependence." },
            { "text": "{(1,1,1),(1,1,1),(1,1,1)}", "weight": 0, "feedback": "All identical ‚Äì rank‚ÄØ=‚ÄØ1." }
          ],
          "points_possible": 4,
          "feedback": "A basis must satisfy both criteria simultaneously."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Choose the correct description of a basis:",
          "answers": [
            { "text": "An independent spanning set.", "weight": 100, "feedback": "By definition ‚Äì guarantees unique coordinates." },
            { "text": "Any maximal independent set whether it spans or not.", "weight": 0, "feedback": "Maximal independence in V *does* imply span, but careful wording matters." },
            { "text": "Any minimal spanning set, independent or not.", "weight": 0, "feedback": "Minimal spanning implies independence; else redundant." },
            { "text": "A set of vectors all with unit length.", "weight": 0, "feedback": "Length isn‚Äôt required; orthonormality is extra structure." }
          ],
          "points_possible": 4,
          "feedback": "Independence + span = basis ‚áí coordinate system."
        }
      ],
      "outcomes": ["linear_independence", "span_and_basis_definition", "rank_nullity_theorem"]
    },

    {
      "id": "inverse-determinant-mastery-check",
      "title": "Matrix Inverses and Determinants Mastery Check",
      "description": "Assesses invertibility criteria, determinant properties, and computation skills.",
      "settings": { "time_limit": 30, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 70,
        "badges": ["inverse_calculator", "determinant_wizard"],
        "completion_message": "Inverse & determinant mastery unlocked ‚Äì singularity no more!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Which condition guarantees a square matrix A is invertible?",
          "answers": [
            { "text": "det(A)‚ÄØ‚â†‚ÄØ0", "weight": 100, "feedback": "Non‚Äëzero determinant ‚áî full rank ‚áî invertible." },
            { "text": "trace(A)‚ÄØ=‚ÄØ0", "weight": 0,   "feedback": "Trace alone says nothing about invertibility." },
            { "text": "A has at least one zero entry.", "weight": 0, "feedback": "Zero entries are allowed; look at determinant." },
            { "text": "A is symmetric.", "weight": 0, "feedback": "Symmetry does not imply invertibility (could have zero eigenvalue)." }
          ],
          "points_possible": 4,
          "feedback": "Know equivalences: pivots, rank, det, eigenvalues."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "If A is 2√ó2 with det(A)=5, what is det(3A)?",
          "answers": [
            { "text": "45", "weight": 100, "feedback": "Scale factor¬≥? No ‚Äì for 2√ó2 det(kA)=k¬≤det(A) ‚áí 3¬≤¬∑5‚ÄØ=‚ÄØ45." },
            { "text": "15", "weight": 0,   "feedback": "Missed square of scale factor." },
            { "text": "5",  "weight": 0,   "feedback": "Ignored scaling effect." },
            { "text": "9",  "weight": 0,   "feedback": "Computed k¬≤ only, forgot det(A)." }
          ],
          "points_possible": 4,
          "feedback": "General rule: det(kA)=k‚Åø det(A) for n√ón matrices."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "If A is invertible, then:",
          "answers": [
            { "text": "A‚Åª¬πA‚ÄØ=‚ÄØI", "weight": 100, "feedback": "Definition of the inverse." },
            { "text": "AA‚ÄØ=‚ÄØI",  "weight": 0,   "feedback": "That statement needs A‚ÄØ=‚ÄØA‚Åª¬π." },
            { "text": "A+I‚ÄØ=‚ÄØ0", "weight": 0,   "feedback": "No such requirement." },
            { "text": "det(A)=0", "weight": 0,   "feedback": "Inverse exists only when det‚ÄØ‚â†‚ÄØ0." }
          ],
          "points_possible": 4,
          "feedback": "Left and right inverses coincide for square full‚Äërank matrices."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "For an upper‚Äëtriangular 4√ó4 matrix, det(A) equals:",
          "answers": [
            { "text": "The product of its diagonal entries.", "weight": 100, "feedback": "Triangular det rule: multiply diagonals." },
            { "text": "Zero.",                               "weight": 0,   "feedback": "Only if one diagonal entry is zero." },
            { "text": "The sum of its diagonal entries.",    "weight": 0,   "feedback": "That‚Äôs the trace, not determinant." },
            { "text": "The product of off‚Äëdiagonal entries.", "weight": 0,  "feedback": "Off‚Äëdiagonals don‚Äôt enter determinant for triangular matrices." }
          ],
          "points_possible": 4,
          "feedback": "Triangular forms simplify determinant and eigenvalue work."
        }
      ],
      "outcomes": ["matrix_inverse", "determinant_computation", "invertibility_criterion"]
    },

    {
      "id": "vector-space-mastery-check",
      "title": "Vector Spaces and Subspaces Mastery Check",
      "description": "Tests formal vector‚Äëspace axioms and subspace identification.",
      "settings": { "time_limit": 25, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 60,
        "badges": ["space_explorer"],
        "completion_message": "Vector‚Äëspace mastery achieved ‚Äì axioms at your command!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Which statement is NOT a vector‚Äëspace axiom?",
          "answers": [
            { "text": "All vectors must have the same length.", "weight": 100, "feedback": "Correct ‚Äì length uniformity isn‚Äôt required." },
            { "text": "Addition is commutative (u+v‚ÄØ=‚ÄØv+u).",   "weight": 0,   "feedback": "That *is* an axiom." },
            { "text": "There exists a zero (additive identity) vector.", "weight": 0, "feedback": "Essential axiom." },
            { "text": "Every vector has an additive inverse.",  "weight": 0,   "feedback": "Also required." }
          ],
          "points_possible": 4,
          "feedback": "Vector‚Äëspace axioms are purely algebraic; magnitude isn‚Äôt stipulated."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Which set is a subspace of ‚Ñù¬≥?",
          "answers": [
            { "text": "{(x,y,z)¬†|¬†2x+3y‚àíz‚ÄØ=‚ÄØ0}", "weight": 100, "feedback": "Plane through origin ‚Äì passes all three subspace tests." },
            { "text": "{(x,y,z)¬†|¬†x¬≤+y¬≤+z¬≤‚ÄØ=‚ÄØ1}", "weight": 0, "feedback": "Unit sphere ‚Äì fails closure tests." },
            { "text": "{(x,y,z)¬†|¬†x>0}",          "weight": 0, "feedback": "Not closed under negative scalars." },
            { "text": "{(x,y,z)¬†|¬†x+y+z‚ÄØ=‚ÄØ1}",     "weight": 0, "feedback": "Fails zero‚Äëvector test." }
          ],
          "points_possible": 4,
          "feedback": "Linear conditions that equal zero often signal subspaces."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "The null space of matrix A is:",
          "answers": [
            { "text": "All vectors x with Ax‚ÄØ=‚ÄØ0.", "weight": 100, "feedback": "Kernel of the linear transformation." },
            { "text": "All non‚Äëzero vectors in the column space.", "weight": 0, "feedback": "Column space is range, not kernel." },
            { "text": "All row vectors of A.",      "weight": 0,   "feedback": "Those form the row space, not null space." },
            { "text": "All vectors orthogonal to column space.", "weight": 0, "feedback": "That‚Äôs left‚Äënull space of A·µÄ." }
          ],
          "points_possible": 4,
          "feedback": "Null space is pivotal for understanding solutions to Ax‚ÄØ=‚ÄØb."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "For subset W¬†‚äÇ¬†V to be a subspace, which condition is NOT necessary?",
          "answers": [
            { "text": "W must be finite.",          "weight": 100, "feedback": "Subspaces can be infinite (e.g., lines)." },
            { "text": "0‚ÄØ‚àà‚ÄØW.",                    "weight": 0,   "feedback": "Zero vector is mandatory." },
            { "text": "Closed under addition.",     "weight": 0,   "feedback": "Essential condition." },
            { "text": "Closed under scalar multiplication.", "weight": 0, "feedback": "Essential condition." }
          ],
          "points_possible": 4,
          "feedback": "Size isn‚Äôt part of the definition ‚Äì properties are."
        }
      ],
      "outcomes": ["vector_space_axioms", "subspace_tests", "null_space_definition"]
    },

    {
      "id": "transformation-mastery-check",
      "title": "Linear Transformations Mastery Check",
      "description": "Covers properties, standard matrices, kernel, range, and rank‚Äënullity insight.",
      "settings": { "time_limit": 30, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 75,
        "badges": ["transformation_mage", "rank_nullity_scholar"],
        "completion_message": "Transformation mastery achieved ‚Äì linear maps obey your command!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "A transformation T:‚Ñù¬≤‚Üí‚Ñù¬≤ rotating vectors 90¬∞ CCW has standard matrix:",
          "answers": [
            { "text": "[[0,‚ÄØ‚àí1], [1,‚ÄØ0]]", "weight": 100, "feedback": "Maps (1,0)‚Üí(0,1) and (0,1)‚Üí(‚àí1,0)." },
            { "text": "[[1,‚ÄØ0], [0,‚ÄØ1]]", "weight": 0,   "feedback": "Identity ‚Äì no rotation." },
            { "text": "[[0,‚ÄØ1], [‚àí1,‚ÄØ0]]", "weight": 0,  "feedback": "Clockwise rotation." },
            { "text": "[[‚àí1,‚ÄØ0], [0,‚ÄØ‚àí1]]", "weight": 0, "feedback": "180¬∞ rotation (negation)." }
          ],
          "points_possible": 4,
          "feedback": "Standard basis images give the columns of the matrix."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Which property is NOT guaranteed by every linear transformation T?",
          "answers": [
            { "text": "Distance preservation.",               "weight": 100, "feedback": "Only orthogonal linear maps preserve length." },
            { "text": "Additivity: T(u+v)=T(u)+T(v).",         "weight": 0,   "feedback": "Additivity is part of definition." },
            { "text": "Homogeneity: T(cu)=c‚ÄØT(u).",            "weight": 0,   "feedback": "Homogeneity is part of definition." },
            { "text": "Maps the zero vector to zero.",         "weight": 0,   "feedback": "Follows from linearity." }
          ],
          "points_possible": 4,
          "feedback": "Not all linear maps are isometries ‚Äì they can stretch or skew."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Kernel(T) is a subspace of:",
          "answers": [
            { "text": "The domain of T.", "weight": 100, "feedback": "Kernel lives where the inputs live." },
            { "text": "The codomain of T.", "weight": 0,  "feedback": "That‚Äôs the range/image." },
            { "text": "Neither ‚Äì it‚Äôs generally not a vector space.", "weight": 0, "feedback": "Kernel is always a subspace." },
            { "text": "Both domain and codomain.", "weight": 0, "feedback": "Only inputs satisfy Ax‚ÄØ=‚ÄØ0." }
          ],
          "points_possible": 4,
          "feedback": "Kernel describes which inputs collapse to zero."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Rank‚Äënullity theorem states:",
          "answers": [
            { "text": "dim‚ÄØKer(T)‚ÄØ+‚ÄØdim‚ÄØIm(T)‚ÄØ=‚ÄØdim‚ÄØDomain", "weight": 100, "feedback": "Classic relation connecting kernel & image." },
            { "text": "rank(A)=trace(A)",                      "weight": 0,   "feedback": "Trace is unrelated to rank in general." },
            { "text": "det(A)=0 implies rank(A)=0",            "weight": 0,   "feedback": "det‚ÄØ=‚ÄØ0 ‚áí rank‚ÄØ<‚ÄØn, not necessarily 0." },
            { "text": "Ker(T)=Im(T)",                          "weight": 0,   "feedback": "Only for rare self‚Äëdual maps." }
          ],
          "points_possible": 4,
          "feedback": "Rank‚Äënullity is the dimension bookkeeping law."
        }
      ],
      "outcomes": ["linear_map_matrix", "kernel_range", "rank_nullity_theorem"]
    },
    {
      "id": "eigen-mastery-check",
      "title": "Eigenvalues and Diagonalization Mastery Check",
      "description": "Focuses on characteristic polynomials, eigenspaces, and diagonalization tests.",
      "settings": { "time_limit": 30, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 80,
        "badges": ["eigen_hunter", "diagonalizer"],
        "completion_message": "Eigen mastery achieved ‚Äì you find invariant directions effortlessly!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Eigenvalues of a 2√ó2 triangular matrix are:",
          "answers": [
            { "text": "Its diagonal entries.", "weight": 100, "feedback": "Triangular matrices have eigenvalues on the diagonal." },
            { "text": "Solutions to det(A)‚ÄØ=‚ÄØ0.", "weight": 0, "feedback": "det(A) gives invertibility, not eigenvalues directly." },
            { "text": "Zeros of trace(A).",      "weight": 0, "feedback": "Trace equals sum of eigenvalues, not their individual values." },
            { "text": "Always ¬±1.",              "weight": 0, "feedback": "Eigenvalues depend on matrix entries." }
          ],
          "points_possible": 4,
          "feedback": "Upper/lower triangular ‚Üí easy eigen‚Äëreading."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Matrix A is diagonalizable iff:",
          "answers": [
            { "text": "It has n linearly independent eigenvectors (in ‚Ñù‚Åø).", "weight": 100, "feedback": "That gives P with full rank ‚áí PDP‚Åª¬π." },
            { "text": "All eigenvalues are distinct.",                      "weight": 0,   "feedback": "Distinct eigenvalues *implies* diagonalizable, but not necessary." },
            { "text": "It is symmetric.",                                 "weight": 0,   "feedback": "Symmetry guarantees orthogonal diagonalization, but non‚Äësymmetric matrices can also diagonalize." },
            { "text": "det(A)=1.",                                         "weight": 0,   "feedback": "Determinant alone says nothing about diagonalizability." }
          ],
          "points_possible": 4,
          "feedback": "Geometric multiplicity must sum to n."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "For A with eigenvalue Œª, eigenspace is:",
          "answers": [
            { "text": "Null space of (A‚àíŒªI).", "weight": 100, "feedback": "Solve (A‚àíŒªI)v=0 for eigenvectors." },
            { "text": "Column space of (A‚àíŒªI).", "weight": 0, "feedback": "That‚Äôs the range, not null space." },
            { "text": "Row space of A.",          "weight": 0, "feedback": "Row space relates to solutions of A·µÄy=0." },
            { "text": "All non‚Äëzero vectors in ‚Ñù‚Åø.", "weight": 0, "feedback": "Eigenvectors satisfy a specific equation." }
          ],
          "points_possible": 4,
          "feedback": "Kernel viewpoint links eigenvectors to familiar null‚Äëspace solving."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "If A has characteristic polynomial (Œª‚Äë2)¬≤(Œª+1), algebraic multiplicity of Œª=2 is:",
          "answers": [
            { "text": "2", "weight": 100, "feedback": "Exponent of (Œª‚Äë2) in the char‚Äëpoly." },
            { "text": "1", "weight": 0,   "feedback": "That‚Äôs multiplicity for distinct root." },
            { "text": "0", "weight": 0,   "feedback": "Œª=2 is clearly a root." },
            { "text": "Depends on geometric multiplicity.", "weight": 0, "feedback": "Geometric multiplicity ‚â§ algebraic multiplicity, not equal by default." }
          ],
          "points_possible": 4,
          "feedback": "Know the difference between algebraic and geometric multiplicities."
        }
      ],
      "outcomes": ["characteristic_polynomial", "eigenspace_concept", "diagonalization_test"]
    },

    {
      "id": "orthogonality-mastery-check",
      "title": "Orthogonality and Gram‚ÄìSchmidt Mastery Check",
      "description": "Explores inner products, orthogonal projections, and QR factorization ideas.",
      "settings": { "time_limit": 30, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 70,
        "badges": ["orthogonality_ace", "qr_fac_master"],
        "completion_message": "Orthogonality mastery achieved ‚Äì right angles all around!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Vectors u and v in ‚Ñù¬≥ are orthogonal when:",
          "answers": [
            { "text": "u¬∑v‚ÄØ=‚ÄØ0.", "weight": 100, "feedback": "Zero dot product ‚áí 90¬∞ angle." },
            { "text": "|u|‚ÄØ=‚ÄØ|v|.", "weight": 0,  "feedback": "Equal length doesn‚Äôt force 90¬∞." },
            { "text": "They lie in the same line.", "weight": 0, "feedback": "That means parallel, not perpendicular." },
            { "text": "u√óv‚ÄØ=‚ÄØ0.", "weight": 0, "feedback": "Cross product zero ‚áí they‚Äôre parallel." }
          ],
          "points_possible": 4,
          "feedback": "Dot product is orthogonality detector."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "The projection of b onto a unit vector u is:",
          "answers": [
            { "text": "(b¬∑u)u", "weight": 100, "feedback": "Scalar component times direction." },
            { "text": "u√ób",    "weight": 0,   "feedback": "Cross product gives orthogonal vector, not projection." },
            { "text": "|b|u",   "weight": 0,   "feedback": "Missing cosine factor." },
            { "text": "b‚ÄØ‚àí‚ÄØ(b¬∑u)u", "weight": 0, "feedback": "That‚Äôs the rejection (orthogonal component)." }
          ],
          "points_possible": 4,
          "feedback": "Projection formula underpins least‚Äësquares and QR."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Gram‚ÄìSchmidt applied to independent set {v‚ÇÅ,v‚ÇÇ} produces:",
          "answers": [
            { "text": "An orthonormal set {q‚ÇÅ,q‚ÇÇ} spanning the same space.", "weight": 100, "feedback": "Goal: orthogonalize and normalize." },
            { "text": "A dependent set because of rounding errors.", "weight": 0, "feedback": "Conceptually remains independent; numerics are separate issue." },
            { "text": "QR factorization with Q upper‚Äëtriangular.", "weight": 0, "feedback": "Q becomes orthogonal, R upper‚Äëtriangular." },
            { "text": "A diagonal matrix of eigenvalues.", "weight": 0, "feedback": "That‚Äôs eigen‚Äëdecomposition, not Gram‚ÄìSchmidt." }
          ],
          "points_possible": 4,
          "feedback": "Orthogonal bases simplify many computations."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Matrix Q in QR factorization is:",
          "answers": [
            { "text": "Orthogonal (Q·µÄQ‚ÄØ=‚ÄØI).", "weight": 100, "feedback": "Columns are orthonormal." },
            { "text": "Upper‚Äëtriangular.",      "weight": 0,   "feedback": "That‚Äôs the R factor." },
            { "text": "Diagonal with singular values.", "weight": 0, "feedback": "Diagonal Œ£ appears in SVD, not QR." },
            { "text": "Always symmetric.",      "weight": 0,   "feedback": "Orthogonal ‚â† symmetric necessarily." }
          ],
          "points_possible": 4,
          "feedback": "Orthogonality ensures numerically stable solves."
        }
      ],
      "outcomes": ["inner_product", "projection_formula", "qr_factorization"]
    },

    {
      "id": "comprehensive-review",
      "title": "Comprehensive Linear Algebra Review",
      "description": "Final comprehensive assessment covering all major linear algebra concepts.",
      "settings": { "time_limit": 60, "shuffle_answers": true, "allowed_attempts": 2 },
      "mastery_criteria": { "passing_score": 80, "unlock_requirement": false },
      "gamification": {
        "xp_value": 100,
        "badges": ["linear_algebra_champion", "synthesis_master"],
        "completion_message": "Congratulations! You have mastered Linear Algebra! üéì"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Which statement best describes the relationship between eigenvalues and matrix invertibility?",
          "answers": [
            { "text": "A matrix is invertible if and only if all eigenvalues are nonzero", "weight": 100, "feedback": "Perfect! Zero eigenvalues indicate the matrix maps some nonzero vector to zero." },
            { "text": "A matrix is invertible if and only if all eigenvalues are positive", "weight": 0, "feedback": "Negative eigenvalues don't prevent invertibility." },
            { "text": "Eigenvalues don't affect invertibility", "weight": 0, "feedback": "Eigenvalues are directly related to invertibility." },
            { "text": "A matrix is invertible if it has real eigenvalues", "weight": 0, "feedback": "Complex eigenvalues don't prevent invertibility." }
          ],
          "points_possible": 5,
          "feedback": "This connects eigenvalue theory with fundamental matrix properties."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "In a least squares problem Ax ‚âà b, the normal equation is:",
          "answers": [
            { "text": "A·µÄAx = A·µÄb", "weight": 100, "feedback": "Correct! This minimizes ||Ax - b||¬≤." },
            { "text": "Ax = b", "weight": 0, "feedback": "This would be exact solution, not least squares." },
            { "text": "AA·µÄx = b", "weight": 0, "feedback": "Wrong transpose placement." },
            { "text": "A·µÄAx = b", "weight": 0, "feedback": "Missing the A·µÄ on the right side." }
          ],
          "points_possible": 5,
          "feedback": "Normal equations arise from projecting onto column space."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "The rank-nullity theorem states that for an m√ón matrix A:",
          "answers": [
            { "text": "rank(A) + nullity(A) = n", "weight": 100, "feedback": "Perfect! Total dimension budget of domain." },
            { "text": "rank(A) + nullity(A) = m", "weight": 0, "feedback": "That would relate to codomain dimension." },
            { "text": "rank(A) √ó nullity(A) = n", "weight": 0, "feedback": "It's addition, not multiplication." },
            { "text": "rank(A) - nullity(A) = n", "weight": 0, "feedback": "It's addition, not subtraction." }
          ],
          "points_possible": 5,
          "feedback": "This fundamental theorem balances kernel and range dimensions."
        }
      ],
      "outcomes": ["synthesis_thinking", "comprehensive_understanding", "application_integration"]
    },

    {
      "id": "row-ops-challenge",
      "title": "Elementary Row Operations Challenge",
      "description": "Stress‚Äëtest your mastery of Gaussian‚Äëelimination subtleties.",
      "settings": { "time_limit": 20, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 40,
        "badges": ["pivot_paladin"],
        "completion_message": "Row‚Äëops mastery unlocked ‚Äì pivots obey your commands!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Which sequence of row operations most efficiently puts\nA = [[1,2],[3,4]] into an upper‚Äëtriangular form?",
          "answers": [
            { "text": "R‚ÇÇ ‚Üê R‚ÇÇ ‚àí 3R‚ÇÅ", "weight": 100, "feedback": "One replacement eliminates the lower‚Äëleft entry." },
            { "text": "Swap R‚ÇÅ and R‚ÇÇ, then scale R‚ÇÅ", "weight": 0, "feedback": "Swapping is unnecessary; scaling wastes a step." },
            { "text": "Scale R‚ÇÇ by 0", "weight": 0, "feedback": "Scaling by 0 destroys information." },
            { "text": "Add R‚ÇÅ to R‚ÇÇ twice", "weight": 0, "feedback": "Twice adds redundant work; once with ‚àí3 factor suffices." }
          ],
          "points_possible": 3,
          "feedback": "Look for the quickest path to zeros below pivots."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "During elimination you encounter a zero pivot. The FIRST remedy is usually:",
          "answers": [
            { "text": "Swap with a lower row that has a non‚Äëzero entry in that column", "weight": 100, "feedback": "Pivoting reorders equations without changing the system." },
            { "text": "Scale the row by 0.1", "weight": 0, "feedback": "Scaling 0 by any factor leaves 0." },
            { "text": "Declare the matrix singular and stop", "weight": 0, "feedback": "A zero pivot may be fixable by swapping; don't quit yet." },
            { "text": "Add the row to itself", "weight": 0, "feedback": "That achieves nothing." }
          ],
          "points_possible": 3,
          "feedback": "Partial pivoting cures zero or tiny pivots to maintain numerical stability."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Which row operation can change the determinant of a matrix by a factor other than ¬±1?",
          "answers": [
            { "text": "Multiplying a row by k ‚â† ¬±1", "weight": 100, "feedback": "Determinant scales by k." },
            { "text": "Adding a multiple of one row to another", "weight": 0, "feedback": "This leaves det unchanged." },
            { "text": "Swapping two rows", "weight": 0, "feedback": "Only flips the sign (factor ‚àí1)." },
            { "text": "Reordering columns", "weight": 0, "feedback": "Column swaps behave like row swaps for det (¬±1 factor)." }
          ],
          "points_possible": 3,
          "feedback": "Keep track of det scaling when computing determinants via elimination."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "In an m√ón matrix (m>n), at most how many non‚Äëzero rows remain after full row‚Äëreduction?",
          "answers": [
            { "text": "n, the number of columns", "weight": 100, "feedback": "Rank ‚â§ min(m,n)." },
            { "text": "m, the original number of rows", "weight": 0, "feedback": "Some rows become zero if m>n." },
            { "text": "m‚àín", "weight": 0, "feedback": "That‚Äôs the lower bound on zero rows, not non‚Äëzero rows." },
            { "text": "Any number up to m+n", "weight": 0, "feedback": "Reduction cannot create more non‚Äëzero rows." }
          ],
          "points_possible": 3,
          "feedback": "Think rank: you cannot have more pivot rows than columns."
        }
      ],
      "outcomes": ["advanced_row_ops", "determinant_tracking", "pivot_strategy"]
    },

    {
      "id": "lu-factorization-mastery-check",
      "title": "LU Factorization Mastery Check",
      "description": "Assess fluency decomposing matrices into Lower and Upper triangular factors.",
      "settings": { "time_limit": 25, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 50,
        "badges": ["lu_legionnaire"],
        "completion_message": "LU mastery achieved ‚Äì split and conquer!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "LU factorization without row swaps exists for a square matrix if and only if:",
          "answers": [
            { "text": "All its leading principal minors are non‚Äëzero", "weight": 100, "feedback": "This guarantees non‚Äëzero pivots during elimination." },
            { "text": "det(A) = 0", "weight": 0, "feedback": "Zero determinant forbids invertibility and LU without pivoting." },
            { "text": "A is symmetric", "weight": 0, "feedback": "Symmetry does not ensure the necessary pivot pattern." },
            { "text": "A has equal row and column sums", "weight": 0, "feedback": "Irrelevant to LU existence." }
          ],
          "points_possible": 4,
          "feedback": "Pivot growth depends on non‚Äëzero leading sub‚Äëdeterminants."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "In the equation PA = LU, the matrix P represents:",
          "answers": [
            { "text": "A permutation matrix tracking row swaps", "weight": 100, "feedback": "Pivoting uses P to record swaps." },
            { "text": "The projection onto the column space of A", "weight": 0, "feedback": "Projection matrices are not generally permutations." },
            { "text": "An orthogonal matrix from QR factorization", "weight": 0, "feedback": "That's a different factorization." },
            { "text": "A diagonal scaling matrix", "weight": 0, "feedback": "Scaling uses D, not P." }
          ],
          "points_possible": 4,
          "feedback": "Partial‚Äëpivot LU equals P‚Äë1LU factoring when swaps occur."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Which advantage does LU give over Gaussian elimination for multiple right‚Äëhand sides b?",
          "answers": [
            { "text": "L and U can be reused to solve Ax=b for many b with only triangular solves", "weight": 100, "feedback": "Factor once, solve cheaply many times." },
            { "text": "It avoids any arithmetic beyond addition", "weight": 0, "feedback": "Triangular solves still need division." },
            { "text": "It always avoids round‚Äëoff error", "weight": 0, "feedback": "Numerical error is merely reduced, not eliminated." },
            { "text": "It makes A automatically orthogonal", "weight": 0, "feedback": "LU does not impose orthogonality." }
          ],
          "points_possible": 3,
          "feedback": "Triangular systems are O(n¬≤) each; factoring is O(n¬≥) once."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "For A = [[4,2],[6,3]] after one elimination step (R‚ÇÇ ‚Üê R‚ÇÇ ‚àí 1.5R‚ÇÅ) the multiplier 1.5 goes where in L?",
          "answers": [
            { "text": "L(2,1) entry", "weight": 100, "feedback": "Lower‚Äëleft stores scaling used to eliminate." },
            { "text": "U(2,1) entry", "weight": 0, "feedback": "U keeps zeros below diagonal after elimination." },
            { "text": "L(1,2) entry", "weight": 0, "feedback": "Super‚Äëdiagonal belongs to U, not L." },
            { "text": "Diagonal of L", "weight": 0, "feedback": "L's diagonal is 1 by convention." }
          ],
          "points_possible": 4,
          "feedback": "Storing multipliers replicates elimination history."
        }
      ],
      "outcomes": ["lu_existence", "permutation_matrix", "triangular_solves"]
    },

    {
      "id": "determinant-advanced-check",
      "title": "Advanced Determinant Properties Check",
      "description": "Probe deeper facts and common pitfalls about determinants.",
      "settings": { "time_limit": 25, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 45,
        "badges": ["det_diviner"],
        "completion_message": "Determinant lore mastered ‚Äì volumes bend to your will!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "If A and B are n√ón matrices, det(AB) equals:",
          "answers": [
            { "text": "det(A)¬∑det(B)", "weight": 100, "feedback": "Multiplicative property." },
            { "text": "det(A) + det(B)", "weight": 0, "feedback": "Addition is false for determinants." },
            { "text": "det(A) ‚àí det(B)", "weight": 0, "feedback": "No subtraction rule exists." },
            { "text": "det(A)¬∑det(B)‚Åª¬π", "weight": 0, "feedback": "That would imply det(AB) = 1." }
          ],
          "points_possible": 3,
          "feedback": "Det behaves like a homomorphism from GL(n) to ."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "det(A·µÄ) is always:",
          "answers": [
            { "text": "Equal to det(A)", "weight": 100, "feedback": "Determinant is unchanged by transpose." },
            { "text": "The negative of det(A)", "weight": 0, "feedback": "Transpose does not flip sign." },
            { "text": "Zero if A is antisymmetric", "weight": 0, "feedback": "Only odd‚Äëdimension skew matrices have zero det." },
            { "text": "Undefined", "weight": 0, "feedback": "Transpose is always defined." }
          ],
          "points_possible": 3,
          "feedback": "Because det is an alternating multilinear form independent of orientation reversal."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "If one column of a matrix is a linear combination of others, then det(A) is:",
          "answers": [
            { "text": "0", "weight": 100, "feedback": "Column dependence ‚áí volume collapses." },
            { "text": "1", "weight": 0, "feedback": "Only identity has det‚ÄØ=‚ÄØ1." },
            { "text": "Non‚Äëzero but unknown sign", "weight": 0, "feedback": "Dependence forces zero exactly." },
            { "text": "Equal to the product of pivot entries", "weight": 0, "feedback": "Product of pivots is zero because one pivot vanishes." }
          ],
          "points_possible": 3,
          "feedback": "Dependence kills orientation volume."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "For any n√ón matrix A and scalar k, which statement is TRUE?",
          "answers": [
            { "text": "det(A + kI) ‚â† det(A) + k det(I) in general", "weight": 100, "feedback": "Determinant is NOT additive." },
            { "text": "det(A + kI) = det(A) + k‚Åø", "weight": 0, "feedback": "No simple additive relation holds." },
            { "text": "det(A + kI) = det(A)¬∑k‚Åø", "weight": 0, "feedback": "Multiplying by kI, not adding, factors out k‚Åø." },
            { "text": "det(A + kI) always equals det(A)", "weight": 0, "feedback": "Adding kI usually changes det." }
          ],
          "points_possible": 4,
          "feedback": "Addition destroys multiplicative structure; beware simplifying incorrectly."
        }
      ],
      "outcomes": ["det_multiplicative", "det_transpose", "det_dependence", "det_nonadditive"]
    },

    {
      "id": "least-squares-mastery-check",
      "title": "Least‚ÄëSquares Problem Mastery Check",
      "description": "Focuses on normal equations, projection, and over‚Äëdetermined systems.",
      "settings": { "time_limit": 30, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 60,
        "badges": ["least_squares_sage"],
        "completion_message": "Least‚Äësquares mastery ‚Äì best‚Äëfit lines are yours to command!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "The normal equations for minimizing ||Ax ‚àí b||‚ÇÇ are:",
          "answers": [
            { "text": "A·µÄA x = A·µÄ b", "weight": 100, "feedback": "Stationary point of squared error." },
            { "text": "Ax = b", "weight": 0, "feedback": "That requires exact fit." },
            { "text": "AA·µÄ x = b", "weight": 0, "feedback": "Dimensions mismatch." },
            { "text": "A x = A b", "weight": 0, "feedback": "Nonsense equation." }
          ],
          "points_possible": 4,
          "feedback": "Derive by setting gradient to zero."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Geometrically, the least‚Äësquares solution projects b onto:",
          "answers": [
            { "text": "The column space of A", "weight": 100, "feedback": "Closest vector in the image of A." },
            { "text": "The null space of A", "weight": 0, "feedback": "Null space is orthogonal complement of rows, not target." },
            { "text": "Row space of A", "weight": 0, "feedback": "Row space lives in domain coordinates." },
            { "text": "Kernel of A·µÄ", "weight": 0, "feedback": "Kernel corresponds to left‚Äënull, not projection target." }
          ],
          "points_possible": 3,
          "feedback": "Error vector is orthogonal to column space."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "If A has full column rank, the matrix A·µÄA is:",
          "answers": [
            { "text": "Symmetric positive‚Äëdefinite", "weight": 100, "feedback": "Full rank ‚áí x·µÄA·µÄAx = ||Ax||¬≤ > 0 for x ‚â† 0." },
            { "text": "Singular", "weight": 0, "feedback": "Full column rank precludes singularity." },
            { "text": "Skew‚Äësymmetric", "weight": 0, "feedback": "A·µÄA is symmetric, not skew." },
            { "text": "Orthogonal", "weight": 0, "feedback": "Orthogonal implies (A·µÄA)=I which rarely holds." }
          ],
          "points_possible": 4,
          "feedback": "SPD nature allows Cholesky or CG solvers."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Which method avoids forming A·µÄA explicitly and is numerically superior?",
          "answers": [
            { "text": "QR factorization of A", "weight": 100, "feedback": "Directly solves Rx = Q·µÄb with better conditioning." },
            { "text": "Cramer‚Äôs Rule", "weight": 0, "feedback": "Impractical for large matrices; uses det." },
            { "text": "Invert A then multiply by b", "weight": 0, "feedback": "A may not be square or invertible." },
            { "text": "Power iteration", "weight": 0, "feedback": "Used for largest eigenvalue, not least squares." }
          ],
          "points_possible": 3,
          "feedback": "Building normal equations squares condition number; QR circumvents."
        }
      ],
      "outcomes": ["normal_equations", "projection_geometry", "spd_property", "qr_vs_normal"]
    },

    {
      "id": "qr-factorization-mastery-check",
      "title": "QR Factorization Mastery Check",
      "description": "Covers Gram‚ÄìSchmidt, orthogonal matrices, and triangular solve usage.",
      "settings": { "time_limit": 25, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 55,
        "badges": ["qr_quartermaster"],
        "completion_message": "QR mastery ‚Äì orthogonality is your ally!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "In the reduced QR factorization A = QR with A m√ón (m‚â•n), the matrix R is:",
          "answers": [
            { "text": "n√ón upper‚Äëtriangular", "weight": 100, "feedback": "Reduced form trims zero rows." },
            { "text": "m√óm diagonal", "weight": 0, "feedback": "R is triangular, not necessarily diagonal." },
            { "text": "n√óm lower‚Äëtriangular", "weight": 0, "feedback": "Shape reversed." },
            { "text": "Orthogonal", "weight": 0, "feedback": "Q, not R, is orthogonal." }
          ],
          "points_possible": 4,
          "feedback": "Reduced QR keeps essential information in compact form."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Which algorithm produces a more numerically stable QR than classical Gram‚ÄìSchmidt?",
          "answers": [
            { "text": "Modified Gram‚ÄìSchmidt", "weight": 100, "feedback": "Re‚Äëorthogonalizes to reduce error accumulation." },
            { "text": "Power method", "weight": 0, "feedback": "Eigenvalue algorithm, not orthogonalization." },
            { "text": "C‚ÄëG algorithm", "weight": 0, "feedback": "Conjugate gradient solves SPD systems." },
            { "text": "LU with partial pivoting", "weight": 0, "feedback": "LU is not orthogonal." }
          ],
          "points_possible": 3,
          "feedback": "Householder QR is even more stable, but MGS beats classical GS."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "If Q is m√ón with orthonormal columns, then Q·µÄQ equals:",
          "answers": [
            { "text": "I‚Çô", "weight": 100, "feedback": "Columns are orthonormal ‚áí inner‚Äëproducts form identity." },
            { "text": "I‚Çò", "weight": 0, "feedback": "Q Q·µÄ = I‚Çò only if Q is square (m=n)." },
            { "text": "Zero matrix", "weight": 0, "feedback": "Orthogonality does not imply zero matrix." },
            { "text": "A diagonal with column norms", "weight": 0, "feedback": "Norms are 1; gives identity." }
          ],
          "points_possible": 3,
          "feedback": "Rectangular Q acts as an isometry on its column space."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Householder reflections are preferred over Gram‚ÄìSchmidt because they:",
          "answers": [
            { "text": "Use orthogonal transformations that perfectly preserve norms", "weight": 100, "feedback": "Eliminates rounding‚Äëinduced loss of orthogonality." },
            { "text": "Require no floating‚Äëpoint arithmetic", "weight": 0, "feedback": "Still rely on FP math." },
            { "text": "Produce lower‚Äëtriangular R", "weight": 0, "feedback": "Output R is upper‚Äëtriangular." },
            { "text": "Avoid vector normalization", "weight": 0, "feedback": "Householder still needs norm calculations." }
          ],
          "points_possible": 4,
          "feedback": "Reflection matrices are perfectly orthogonal up to machine precision."
        }
      ],
      "outcomes": ["qr_shapes", "mgs_vs_gs", "orthogonal_properties", "householder_advantages"]
    },

    {
      "id": "svd-mastery-check",
      "title": "Singular Value Decomposition Mastery Check",
      "description": "Targets UŒ£V·µÄ structure, interpretation, and applications.",
      "settings": { "time_limit": 30, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 70,
        "badges": ["svd_summoner"],
        "completion_message": "SVD mastery ‚Äì you now decompose anything!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "The non‚Äëzero singular values of A equal the square roots of non‚Äëzero eigenvalues of:",
          "answers": [
            { "text": "A·µÄA", "weight": 100, "feedback": "Symmetric positive‚Äësemidefinite produces real eigenvalues." },
            { "text": "A", "weight": 0, "feedback": "Eigenvalues of A can be complex and signed." },
            { "text": "AA·µÄ ‚àí I", "weight": 0, "feedback": "Irrelevant subtractive shift." },
            { "text": "A + A·µÄ", "weight": 0, "feedback": "This is the symmetric part, not used in SVD calculation." }
          ],
          "points_possible": 4,
          "feedback": "SVD links to principal component directions."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "In A = U Œ£ V·µÄ, the columns of V are:",
          "answers": [
            { "text": "Right singular vectors", "weight": 100, "feedback": "They diagonalize A·µÄA." },
            { "text": "Left singular vectors", "weight": 0, "feedback": "Left singular vectors are columns of U." },
            { "text": "Eigenvectors of A with eigenvalue 1", "weight": 0, "feedback": "Only true in special cases (orthogonal A)." },
            { "text": "Null vectors of A", "weight": 0, "feedback": "Null vectors correspond to zero singular values." }
          ],
          "points_possible": 4,
          "feedback": "Right vs. left depends on which side of Œ£ they multiply."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Low‚Äërank approximation via SVD keeps:",
          "answers": [
            { "text": "The k largest singular values and corresponding singular vectors", "weight": 100, "feedback": "Eckart‚ÄìYoung theorem gives best rank‚Äëk approximation." },
            { "text": "The k smallest singular values", "weight": 0, "feedback": "Small values contribute least to norm." },
            { "text": "Random singular values", "weight": 0, "feedback": "Random retention rarely optimal." },
            { "text": "All singular values but discards vectors", "weight": 0, "feedback": "Need vectors for reconstruction." }
          ],
          "points_possible": 4,
          "feedback": "Applications include image compression and PCA."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Condition number Œ∫‚ÇÇ(A) equals:",
          "answers": [
            { "text": "œÉ_max / œÉ_min", "weight": 100, "feedback": "Largest over smallest singular value (non‚Äëzero)." },
            { "text": "det(A)", "weight": 0, "feedback": "Det relates to product, not ratio, of œÉ_i." },
            { "text": "trace(A)", "weight": 0, "feedback": "Trace sums diagonal entries, unrelated to Œ∫." },
            { "text": "œÉ_max ¬∑ œÉ_min", "weight": 0, "feedback": "Product is 1/|det(A)| for square A, not Œ∫." }
          ],
          "points_possible": 4,
          "feedback": "Œ∫ measures sensitivity of solutions to Ax = b."
        }
      ],
      "outcomes": ["svd_eigen_relation", "singular_vectors_roles", "low_rank_approx", "condition_number"]
    },

    {
      "id": "orthogonal-diagonalization-check",
      "title": "Orthogonal Diagonalization Check",
      "description": "Tests symmetric matrices, eigenbasis existence, and quadratic forms.",
      "settings": { "time_limit": 25, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 50,
        "badges": ["ortho_diag_oracle"],
        "completion_message": "Orthogonal diagonalization mastered ‚Äì quadratic forms simplified!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "A real symmetric matrix A is always:",
          "answers": [
            { "text": "Orthogonally diagonalizable", "weight": 100, "feedback": "Spectral theorem." },
            { "text": "Skew‚Äësymmetric", "weight": 0, "feedback": "Skew means A·µÄ = ‚àíA, opposite property." },
            { "text": "Defective (not diagonalizable)", "weight": 0, "feedback": "Symmetric matrices never defective over ‚Ñù." },
            { "text": "Upper‚Äëtriangular with zeros below diagonal", "weight": 0, "feedback": "Symmetry relates upper to lower." }
          ],
          "points_possible": 4,
          "feedback": "Eigenvectors can be chosen orthonormal."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Eigenvalues of a symmetric matrix are always:",
          "answers": [
            { "text": "Real", "weight": 100, "feedback": "A·µÄ=A ‚áí characteristic polynomial has real roots." },
            { "text": "Purely imaginary", "weight": 0, "feedback": "Imaginary arise in skew‚Äësymmetric case." },
            { "text": "Negative", "weight": 0, "feedback": "Sign depends on definiteness." },
            { "text": "Zero", "weight": 0, "feedback": "Only if matrix is singular." }
          ],
          "points_possible": 3,
          "feedback": "Positive‚Äëdefinite ‚Üî all eigenvalues positive."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Quadratic form x·µÄAx can be written as Œ£ Œª·µ¢ y·µ¢¬≤ after change of variables y = Q·µÄx when:",
          "answers": [
            { "text": "Q is orthogonal and diagonalizes A", "weight": 100, "feedback": "Completing the square in eigenbasis." },
            { "text": "Q contains pivot columns of A", "weight": 0, "feedback": "Pivot columns need not be orthonormal." },
            { "text": "A is any rectangular matrix", "weight": 0, "feedback": "Quadratic form requires square A." },
            { "text": "Q is triangular", "weight": 0, "feedback": "Triangular Q not guaranteed orthogonality." }
          ],
          "points_possible": 4,
          "feedback": "Diagonalization simplifies optimization of quadratic forms."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Positive‚Äëdefinite symmetric A satisfies which equivalent test?",
          "answers": [
            { "text": "All leading principal minors are positive", "weight": 100, "feedback": "Sylvester‚Äôs criterion." },
            { "text": "det(A) < 0", "weight": 0, "feedback": "Det must be positive for PD." },
            { "text": "trace(A) < 0", "weight": 0, "feedback": "Trace not decisive alone." },
            { "text": "A¬≤ has negative eigenvalues", "weight": 0, "feedback": "Squares make eigenvalues non‚Äënegative." }
          ],
          "points_possible": 4,
          "feedback": "Several equivalent PD tests exist: eigenvalues >0, x·µÄAx>0, Sylvester."
        }
      ],
      "outcomes": ["spectral_theorem", "eigenvalue_reality", "quadratic_form_diag", "pd_tests"]
    },

    {
      "id": "complex-eigen-mastery-check",
      "title": "Complex Eigenvalues & 2√ó2 Rotation‚ÄëScaling Check",
      "description": "Handles cases when eigenvalues are complex and relates them to real Jordan blocks.",
      "settings": { "time_limit": 25, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 55,
        "badges": ["complex_eigen_cartographer"],
        "completion_message": "Complex eigen mastery unlocked ‚Äì rotations decoded!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "The real matrix [[0, -1],[1, 0]] has eigenvalues:",
          "answers": [
            { "text": "¬± i", "weight": 100, "feedback": "Rotation by 90¬∞ has purely imaginary eigenvalues." },
            { "text": "¬±1", "weight": 0, "feedback": "Those correspond to reflections." },
            { "text": "0 and 1", "weight": 0, "feedback": "Trace = 0 but det = 1." },
            { "text": "¬±‚àö2", "weight": 0, "feedback": "No such eigenvalues for pure rotation." }
          ],
          "points_possible": 3,
          "feedback": "Characteristic equation Œª¬≤+1=0."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "A 2√ó2 matrix with eigenvalues a ¬± ib (b‚â†0) is similar over ‚Ñù to:",
          "answers": [
            { "text": "[[a, -b],[b, a]]", "weight": 100, "feedback": "Real Jordan block representing rotation‚Äëscaling." },
            { "text": "Diagonal matrix with a and b", "weight": 0, "feedback": "Complex eigenvalues cannot appear on real diagonal." },
            { "text": "Upper triangular with a‚Äôs on diagonal and 1 above", "weight": 0, "feedback": "That would be defective, not complex pair." },
            { "text": "Identity matrix", "weight": 0, "feedback": "Identity eigenvalues are 1." }
          ],
          "points_possible": 4,
          "feedback": "Block encodes magnitude ‚àö(a¬≤+b¬≤) and angle arctan(b/a)."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "For the matrix [[Œª, -Œº],[Œº, Œª]] with Œº ‚â† 0, its determinant equals:",
          "answers": [
            { "text": "Œª¬≤ + Œº¬≤", "weight": 100, "feedback": "Compute: Œª¬≤ + Œº¬≤." },
            { "text": "Œª¬≤ - Œº¬≤", "weight": 0, "feedback": "Sign error for cross terms." },
            { "text": "2ŒªŒº", "weight": 0, "feedback": "That is 2√ó off‚Äëdiag product." },
            { "text": "Œº¬≤ - Œª¬≤", "weight": 0, "feedback": "Also wrong sign." }
          ],
          "points_possible": 3,
          "feedback": "Rotation‚Äëscaling matrices have positive determinant."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Such a matrix represents (for Œº‚â†0):",
          "answers": [
            { "text": "A rotation combined with uniform scaling", "weight": 100, "feedback": "Angle via atan2(Œº,Œª), scale via ‚àö(Œª¬≤+Œº¬≤)." },
            { "text": "A shear", "weight": 0, "feedback": "Shear has det = 1 and eigenvalue 1." },
            { "text": "Pure reflection", "weight": 0, "feedback": "Reflection has eigenvalues ¬±1." },
            { "text": "Projection onto a line", "weight": 0, "feedback": "Projection has idempotent property." }
          ],
          "points_possible": 4,
          "feedback": "Complex eigenvalues encode rotation in real plane."
        }
      ],
      "outcomes": ["complex_eigenvalues", "real_block_form", "rotation_scaling_det", "geom_interpretation"]
    },

    {
      "id": "change-of-basis-check",
      "title": "Change‚Äëof‚ÄëBasis & Coordinates Check",
      "description": "Handles transition matrices and coordinate vector conversion.",
      "settings": { "time_limit": 25, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 45,
        "badges": ["basis_shifter"],
        "completion_message": "Change‚Äëof‚Äëbasis mastery ‚Äì coordinates translate at your whim!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Columns of the change‚Äëof‚Äëbasis matrix from B to C consist of:",
          "answers": [
            { "text": "Coordinate vectors of B‚Äôs basis expressed in C", "weight": 100, "feedback": "Convert each B‚Äëvector into C‚Äëcoordinates." },
            { "text": "Coordinate vectors of C expressed in B", "weight": 0, "feedback": "Order matters." },
            { "text": "Any orthonormal set", "weight": 0, "feedback": "Matrices need not be orthonormal; they encode coordinates." },
            { "text": "Eigenvectors of A", "weight": 0, "feedback": "Unrelated unless B chosen as eigenbasis." }
          ],
          "points_possible": 4,
          "feedback": "Make sure you know ‚Äòfrom‚Äô and ‚Äòto‚Äô conventions."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "If P changes coordinates from basis B to standard and [x]_B is known, then x equals:",
          "answers": [
            { "text": "P [x]_B", "weight": 100, "feedback": "Multiply by matrix mapping B‚Äëcoords to standard." },
            { "text": "P‚Åª¬π [x]_B", "weight": 0, "feedback": "Inverse goes the opposite direction." },
            { "text": "[x]_B P", "weight": 0, "feedback": "Vectors multiply on right only if row‚Äëvector convention." },
            { "text": "P·µÄ [x]_B", "weight": 0, "feedback": "Transpose appears in orthogonal changes, not general." }
          ],
          "points_possible": 3,
          "feedback": "Left‚Äëmultiply column coordinate vector."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Similarity A' = P‚Åª¬π A P represents:",
          "answers": [
            { "text": "Matrix of the same linear map in a new basis", "weight": 100, "feedback": "Coordinates change, map unchanged." },
            { "text": "A different linear transformation altogether", "weight": 0, "feedback": "Underlying map is identical." },
            { "text": "Row equivalence", "weight": 0, "feedback": "Similarity is stronger than row equivalence." },
            { "text": "Permutation of rows only", "weight": 0, "feedback": "Column transformation also present." }
          ],
          "points_possible": 3,
          "feedback": "Similarity preserves eigenvalues and determinant."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Determinant satisfies det(A') = det(A) under similarity because:",
          "answers": [
            { "text": "det(P‚Åª¬π)det(A)det(P) = det(A)", "weight": 100, "feedback": "det(P‚Åª¬π)=1/det(P) gives cancellation." },
            { "text": "det(P) always equals 1", "weight": 0, "feedback": "Permutation matrices have ¬±1, but P is arbitrary invertible." },
            { "text": "Similarity adds zero rows", "weight": 0, "feedback": "No row ops occur." },
            { "text": "trace also preserved", "weight": 0, "feedback": "Trace is preserved too but not the reason for det." }
          ],
          "points_possible": 4,
          "feedback": "Determinant is basis‚Äëindependent."
        }
      ],
      "outcomes": ["change_of_basis_matrix", "coordinate_conversion", "similarity_transforms", "det_invariant"]
    },

    {
      "id": "block-matrix-mastery-check",
      "title": "Block Matrix Operations Mastery Check",
      "description": "Examines partitioned matrices, Schur complements, and block inverses.",
      "settings": { "time_limit": 30, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 60,
        "badges": ["block_baron"],
        "completion_message": "Block‚Äëmatrix mastery ‚Äì partitioned calculations simplified!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "Which condition allows the block inverse formula\n[[A, B],[C, D]]‚Åª¬π to use the Schur complement S = D ‚àí C A‚Åª¬π B?",
          "answers": [
            { "text": "A is invertible", "weight": 100, "feedback": "Need A‚Åª¬π to define S." },
            { "text": "B is zero", "weight": 0, "feedback": "Then formula simplifies but not required." },
            { "text": "C equals B·µÄ", "weight": 0, "feedback": "Symmetry not mandatory for Schur." },
            { "text": "det(D)=0", "weight": 0, "feedback": "Would break S invertibility later." }
          ],
          "points_possible": 4,
          "feedback": "Dual version exists if D invertible instead."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Block diagonal matrices‚Äô determinants equal:",
          "answers": [
            { "text": "Product of determinants of each diagonal block", "weight": 100, "feedback": "Blocks act like independent sub‚Äëmatrices." },
            { "text": "Sum of determinants of blocks", "weight": 0, "feedback": "Addition incorrect." },
            { "text": "Zero if any off‚Äëdiagonal block non‚Äëzero", "weight": 0, "feedback": "Off‚Äëdiagonals are zero in block diagonal." },
            { "text": "Trace of whole matrix", "weight": 0, "feedback": "Trace unrelated." }
          ],
          "points_possible": 3,
          "feedback": "Determinant factorizes over block diagonal structure."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Multiplying two conformable block matrices requires:",
          "answers": [
            { "text": "Matching inner block dimensions pairwise", "weight": 100, "feedback": "Sub‚Äëblocks multiply like scalars with sum." },
            { "text": "All blocks to be square", "weight": 0, "feedback": "Rectangular blocks allowed if dimensions fit." },
            { "text": "Blocks to be diagonal", "weight": 0, "feedback": "Only needed for simplification, not requirement." },
            { "text": "Blocks to commute", "weight": 0, "feedback": "Non‚Äëcommutative blocks still multiply." }
          ],
          "points_possible": 3,
          "feedback": "Picture each block as a ‚Äòsuper‚Äëentry‚Äô with its own shape."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "The Schur complement S of block D in M = [[A,B],[C,D]] is positive‚Äëdefinite if:",
          "answers": [
            { "text": "M is positive‚Äëdefinite and A is invertible", "weight": 100, "feedback": "PD carries to its Schur complement." },
            { "text": "D is singular", "weight": 0, "feedback": "Singularity obstructs PD in S." },
            { "text": "Only A is PD", "weight": 0, "feedback": "Need entire M PD." },
            { "text": "B and C are zero", "weight": 0, "feedback": "Then S=D, condition different." }
          ],
          "points_possible": 4,
          "feedback": "Useful in statistics (covariance conditioning)."
        }
      ],
      "outcomes": ["schur_complement", "block_det", "block_mult_dims", "schur_pd"]
    },

    {
      "id": "conditioning-check",
      "title": "Numerical Conditioning & Stability Check",
      "description": "Explores condition numbers, floating‚Äëpoint pitfalls, and solver choices.",
      "settings": { "time_limit": 25, "shuffle_answers": true, "allowed_attempts": 3 },
      "mastery_criteria": { "passing_score": 75, "unlock_requirement": true },
      "gamification": {
        "xp_value": 50,
        "badges": ["condition_keeper"],
        "completion_message": "Conditioning mastered ‚Äì computations stay stable!"
      },
      "questions": [
        {
          "type": "multiple_choice_question",
          "question_text": "High condition number indicates:",
          "answers": [
            { "text": "Small relative changes in data cause large relative changes in solution", "weight": 100, "feedback": "Ill‚Äëconditioning amplifies error." },
            { "text": "Matrix is always singular", "weight": 0, "feedback": "Singular ‚Üí Œ∫ = ‚àû, but high finite Œ∫ means nearly singular." },
            { "text": "Matrix multiplication is commutative", "weight": 0, "feedback": "No relation." },
            { "text": "LU without pivoting is safe", "weight": 0, "feedback": "Ill‚Äëconditioning demands pivoting/stable methods." }
          ],
          "points_possible": 3,
          "feedback": "Well‚Äëconditioned: Œ∫ near 1; ill‚Äëconditioned: Œ∫ ‚â´ 1."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Which factorization typically gives the MOST stable solution to Ax=b?",
          "answers": [
            { "text": "QR via Householder reflections", "weight": 100, "feedback": "Orthogonality preserves norms, minimizing growth." },
            { "text": "LU without pivoting", "weight": 0, "feedback": "Unstable for certain matrices." },
            { "text": "Cramer's Rule", "weight": 0, "feedback": "Catastrophically unstable for large n." },
            { "text": "Explicit inverse multiplication", "weight": 0, "feedback": "Poor accuracy; avoid forming A‚Åª¬π." }
          ],
          "points_possible": 3,
          "feedback": "Orthogonal methods minimise error amplification."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Rounding error in Gaussian elimination is mitigated by:",
          "answers": [
            { "text": "Partial (or complete) pivoting", "weight": 100, "feedback": "Swapping rows keeps pivots large." },
            { "text": "Using single‚Äëprecision floats", "weight": 0, "feedback": "Lower precision worsens error." },
            { "text": "Avoiding row swaps entirely", "weight": 0, "feedback": "Makes matters worse." },
            { "text": "Determinant scaling", "weight": 0, "feedback": "Det knowledge does not fix round‚Äëoff." }
          ],
          "points_possible": 4,
          "feedback": "Pivoting chooses largest available pivot element."
        },
        {
          "type": "multiple_choice_question",
          "question_text": "Machine epsilon Œµ roughly measures:",
          "answers": [
            { "text": "Smallest positive number where 1 + Œµ ‚â† 1 in floating‚Äëpoint arithmetic", "weight": 100, "feedback": "Unit round‚Äëoff definition." },
            { "text": "Smallest non‚Äëzero representable number", "weight": 0, "feedback": "That is min sub‚Äënormal, not Œµ." },
            { "text": "Largest representable number", "weight": 0, "feedback": "That is overflow limit." },
            { "text": "Additive inverse of overflow", "weight": 0, "feedback": "N/A." }
          ],
          "points_possible": 4,
          "feedback": "Œµ ‚âà 2‚Åª‚Åµ¬≥ ‚âà 1.11e‚Äë16 in double precision."
        }
      ],
      "outcomes": ["condition_number_def", "stable_solvers", "pivoting_strategy", "machine_epsilon"]
    }
  ]
}
